{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonkrohn/DLTFpT/blob/master/notebooks/deep_net_in_pytorch_with_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkIRIR7XxpP0"
      },
      "source": [
        "# Deep Neural Network in PyTorch with GPU\n",
        "\n",
        "In this notebook, we decrease the training time of the [Deep Net in PyTorch](https://github.com/jonkrohn/DLTFpT/blob/master/notebooks/deep_net_in_pytorch.ipynb) by enabling GPU training as well as mixed-precision training (uses lower-precision data types, e.g., `float16`, for some of the calculations, which can improve performance without significantly affecting model accuracy).\n",
        "\n",
        "**In Colab, be sure to update the Runtime to use an accelerator.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJv0N43uyVsy"
      },
      "source": [
        "#### Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAh1QLwWyYvY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Nh_zNUyarq"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vBWZlFGydPY"
      },
      "outputs": [],
      "source": [
        "train = MNIST('data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test = MNIST('data', train=False, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi5GT2I_yobV"
      },
      "source": [
        "#### Batch data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbqPKnEXy9i6"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train, batch_size=128) \n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=128) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgJkRG_hzM1r"
      },
      "source": [
        "#### Design neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TnSFYGpzRMD"
      },
      "outputs": [],
      "source": [
        "n_input = 784\n",
        "n_dense_1 = 64\n",
        "n_dense_2 = 64\n",
        "n_dense_3 = 64\n",
        "n_out = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAFJBtBYzYcc"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    \n",
        "    # first hidden layer: \n",
        "    nn.Linear(n_input, n_dense_1), \n",
        "    nn.ReLU(), \n",
        "    nn.BatchNorm1d(n_dense_1),\n",
        "    \n",
        "    # second hidden layer: \n",
        "    nn.Linear(n_dense_1, n_dense_2), \n",
        "    nn.ReLU(), \n",
        "    nn.BatchNorm1d(n_dense_2),\n",
        "    \n",
        "    # third hidden layer: \n",
        "    nn.Linear(n_dense_2, n_dense_3), \n",
        "    nn.ReLU(), \n",
        "    nn.BatchNorm1d(n_dense_3),\n",
        "    nn.Dropout(),  \n",
        "    \n",
        "    # output layer: \n",
        "    nn.Linear(n_dense_3, n_out) \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6CQNoYf7qee",
        "outputId": "00ecf587-fc58-4640-8f1f-7f9383a87512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "wid-Rq3p7jTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjfVGdDp0YDJ",
        "outputId": "01cf4cbb-2d43-4bf6-c621-6afd58988fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                   [-1, 64]          50,240\n",
            "              ReLU-2                   [-1, 64]               0\n",
            "       BatchNorm1d-3                   [-1, 64]             128\n",
            "            Linear-4                   [-1, 64]           4,160\n",
            "              ReLU-5                   [-1, 64]               0\n",
            "       BatchNorm1d-6                   [-1, 64]             128\n",
            "            Linear-7                   [-1, 64]           4,160\n",
            "              ReLU-8                   [-1, 64]               0\n",
            "       BatchNorm1d-9                   [-1, 64]             128\n",
            "          Dropout-10                   [-1, 64]               0\n",
            "           Linear-11                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 59,594\n",
            "Trainable params: 59,594\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.23\n",
            "Estimated Total Size (MB): 0.24\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, input_size=(n_input,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzT_k2fF0gT1"
      },
      "source": [
        "#### Configure training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS9m8bPd0j-T"
      },
      "outputs": [],
      "source": [
        "cost_fxn = nn.CrossEntropyLoss() # includes softmax activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AKQugeh0lhM"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVVGdPLI0oLk"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxZMGQHd0s_b"
      },
      "outputs": [],
      "source": [
        "def accuracy_pct(pred_y, true_y):\n",
        "  _, prediction = torch.max(pred_y, 1) # returns maximum values, indices; fed tensor, dim to reduce\n",
        "  correct = (prediction == true_y).sum().item()\n",
        "  return (correct / true_y.shape[0]) * 100.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "481O1w790pvJ",
        "outputId": "b80b6bb4-2167-4ba0-e335-2087c258013b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "469"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "n_batches = len(train_loader)\n",
        "n_batches"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for mixed-precision training: \n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "id": "90r0LX6n-snN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K-f-uJb0x7A",
        "outputId": "50ce85d5-b0c3-48d2-e709-80784a7bcc6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10 epochs. \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 1/10 complete. Cost: 0.384, Accuracy: 89.6%, Time: 13.17 seconds \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 2/10 complete. Cost: 0.154, Accuracy: 95.6%, Time: 9.34 seconds \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 3/10 complete. Cost: 0.116, Accuracy: 96.7%, Time: 9.44 seconds \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 4/10 complete. Cost: 0.091, Accuracy: 97.4%, Time: 9.40 seconds \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 5/10 complete. Cost: 0.078, Accuracy: 97.8%, Time: 9.15 seconds \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 6/10 complete. Cost: 0.066, Accuracy: 98.1%, Time: 9.50 seconds \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 7/10 complete. Cost: 0.058, Accuracy: 98.3%, Time: 9.87 seconds \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 8/10 complete. Cost: 0.051, Accuracy: 98.5%, Time: 9.47 seconds \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 9/10 complete. Cost: 0.045, Accuracy: 98.6%, Time: 8.63 seconds \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 10/10 complete. Cost: 0.043, Accuracy: 98.7%, Time: 9.51 seconds \n",
            "\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 10 \n",
        "\n",
        "print('Training for {} epochs. \\n'.format(n_epochs))\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  start_time = time.time()\n",
        "  \n",
        "  avg_cost = 0.0\n",
        "  avg_accuracy = 0.0\n",
        "  \n",
        "  for i, (X, y) in enumerate(train_loader): # enumerate() provides count of iterations  \n",
        "\n",
        "    # move the input data and labels to the GPU:\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    X_flat = X.view(X.shape[0], -1)\n",
        "    \n",
        "    # forward propagation, NOW WITH autocast automated mixed-precision: \n",
        "    with autocast():\n",
        "      y_hat = model(X_flat)\n",
        "      cost = cost_fxn(y_hat, y)\n",
        "\n",
        "    avg_cost += cost / n_batches\n",
        "    \n",
        "    # backprop and optimization via gradient descent: \n",
        "    optimizer.zero_grad() # set gradients to zero; .backward() accumulates them in buffers\n",
        "    scaler.scale(cost).backward() # scale the gradients so that, with low precision, they don't become so small that the vanish (underflow)\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update() # checks if overflow (inf or NaN values) occurred in previous iteration; reduces scale factor if so\n",
        "    \n",
        "    # calculate accuracy metric:\n",
        "    accuracy = accuracy_pct(y_hat, y)\n",
        "    avg_accuracy += accuracy / n_batches\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "      print('Step {}'.format(i + 1))\n",
        "\n",
        "  end_time = time.time()\n",
        "  time_delta = end_time - start_time\n",
        "    \n",
        "  print('Epoch {}/{} complete. Cost: {:.3f}, Accuracy: {:.1f}%, Time: {:.2f} seconds \\n'\n",
        "        .format(epoch + 1, n_epochs, avg_cost, avg_accuracy, time_delta)) \n",
        "\n",
        "print('Training complete.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKqQEbxY0ris"
      },
      "source": [
        "#### Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5RxXcEy04UM",
        "outputId": "181e8bb8-2ff9-43c7-9f54-6ee825bfbf71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "n_test_batches = len(test_loader)\n",
        "n_test_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqeluNIm06pT",
        "outputId": "3e1ddc34-fb67-4eec-a296-7cefb11a14eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test cost: 0.103, Test accuracy: 97.3%\n"
          ]
        }
      ],
      "source": [
        "model.eval() # disables dropout and batch norm\n",
        "\n",
        "with torch.no_grad(): # disables autograd, reducing memory consumption\n",
        "  \n",
        "  avg_test_cost = 0.0\n",
        "  avg_test_acc = 0.0\n",
        "  \n",
        "  for X, y in test_loader:\n",
        "    \n",
        "    # move the input data and labels to the GPU:\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # make predictions: \n",
        "    X_flat = X.view(X.shape[0], -1)\n",
        "    y_hat = model(X_flat)\n",
        "    \n",
        "    # calculate cost: \n",
        "    cost = cost_fxn(y_hat, y)\n",
        "    avg_test_cost += cost / n_test_batches\n",
        "    \n",
        "    # calculate accuracy:\n",
        "    test_accuracy = accuracy_pct(y_hat, y)\n",
        "    avg_test_acc += test_accuracy / n_test_batches\n",
        "\n",
        "print('Test cost: {:.3f}, Test accuracy: {:.1f}%'.format(avg_test_cost, avg_test_acc))\n",
        "\n",
        "# model.train() # 'undoes' model.eval()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}